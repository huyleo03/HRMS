import * as faceapi from 'face-api.js';

class FaceRecognitionService {
  constructor() {
    this.isModelsLoaded = false;
    // Models ƒë√£ ƒë∆∞·ª£c clone v·ªÅ local b·∫±ng degit
    this.MODEL_URL = '/models';
  }

  /**
   * Load Face-API models (ch·ªâ load 1 l·∫ßn)
   */
  async loadModels() {
    if (this.isModelsLoaded) {
      console.log('‚úÖ Models already loaded');
      return;
    }

    try {
      console.log('üì• Loading Face-API models...');
      
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(`${this.MODEL_URL}/tiny_face_detector`),
        faceapi.nets.faceLandmark68Net.loadFromUri(`${this.MODEL_URL}/face_landmark_68`),
        faceapi.nets.faceRecognitionNet.loadFromUri(`${this.MODEL_URL}/face_recognition`),
      ]);
      
      this.isModelsLoaded = true;
      console.log('‚úÖ Face-API models loaded successfully');
    } catch (error) {
      console.error('‚ùå Error loading Face-API models:', error);
      throw new Error('Kh√¥ng th·ªÉ t·∫£i models AI. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet.');
    }
  }

  /**
   * Detect face t·ª´ base64 image
   */
  async detectFace(base64Image) {
    await this.loadModels();

    try {
      // Convert base64 to Image element
      const img = await this.base64ToImage(base64Image);

      // Detect face v·ªõi descriptor
      const detection = await faceapi
        .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions({
          inputSize: 320,
          scoreThreshold: 0.5
        }))
        .withFaceLandmarks()
        .withFaceDescriptor();

      return detection;
    } catch (error) {
      console.error('‚ùå Face detection error:', error);
      throw error;
    }
  }

  /**
   * So s√°nh 2 khu√¥n m·∫∑t
   * @param {string} profilePhoto - Base64 image t·ª´ profile
   * @param {string} checkInPhoto - Base64 image t·ª´ check-in
   * @param {number} threshold - Ng∆∞·ª°ng so s√°nh (0.4-0.7), c√†ng nh·ªè c√†ng kh·∫Øt khe
   * @returns {Object} K·∫øt qu·∫£ so s√°nh
   */
  async compareFaces(profilePhoto, checkInPhoto, threshold = 0.6) {
    try {
      console.log('üîç Starting face comparison...');
      await this.loadModels();

      // Detect faces t·ª´ c·∫£ 2 ·∫£nh
      console.log('üì∏ Detecting face in profile photo...');
      const profileDetection = await this.detectFace(profilePhoto);

      console.log('üì∏ Detecting face in check-in photo...');
      const checkInDetection = await this.detectFace(checkInPhoto);

      // Ki·ªÉm tra c√≥ detect ƒë∆∞·ª£c kh√¥ng
      if (!profileDetection) {
        return {
          success: false,
          isMatch: false,
          message: 'Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh h·ªì s∆°. Vui l√≤ng c·∫≠p nh·∫≠t ·∫£nh ƒë·∫°i di·ªán r√µ r√†ng h∆°n.',
          similarity: 0,
        };
      }

      if (!checkInDetection) {
        return {
          success: false,
          isMatch: false,
          message: 'Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh ch·∫•m c√¥ng. Vui l√≤ng ch·ª•p l·∫°i v·ªõi khu√¥n m·∫∑t r√µ r√†ng.',
          similarity: 0,
        };
      }

      // T√≠nh kho·∫£ng c√°ch Euclidean gi·ªØa 2 face descriptors
      const distance = faceapi.euclideanDistance(
        profileDetection.descriptor,
        checkInDetection.descriptor
      );

      // Convert distance sang % similarity
      const similarity = Math.max(0, ((1 - distance) * 100));
      const isMatch = distance < threshold;

      console.log('üìä Face comparison result:', {
        distance: distance.toFixed(4),
        similarity: similarity.toFixed(1) + '%',
        threshold,
        isMatch,
      });

      return {
        success: true,
        isMatch,
        distance: parseFloat(distance.toFixed(4)),
        similarity: parseFloat(similarity.toFixed(1)),
        threshold,
        message: isMatch
          ? `‚úÖ X√°c th·ª±c th√†nh c√¥ng! ƒê·ªô t∆∞∆°ng ƒë·ªìng: ${similarity.toFixed(1)}%`
          : `‚ùå Khu√¥n m·∫∑t kh√¥ng kh·ªõp! ƒê·ªô t∆∞∆°ng ƒë·ªìng: ${similarity.toFixed(1)}% (y√™u c·∫ßu t·ªëi thi·ªÉu ${((1 - threshold) * 100).toFixed(0)}%)`,
      };
    } catch (error) {
      console.error('‚ùå Face comparison error:', error);
      return {
        success: false,
        isMatch: false,
        message: 'L·ªói khi so s√°nh khu√¥n m·∫∑t: ' + error.message,
        similarity: 0,
      };
    }
  }

  /**
   * Helper: Convert base64 to Image element
   * N·∫øu l√† URL external, fetch qua proxy ƒë·ªÉ tr√°nh CORS
   */
  async base64ToImage(base64) {
    return new Promise(async (resolve, reject) => {
      const img = new Image();
      
      // N·∫øu l√† URL external (kh√¥ng ph·∫£i base64), fetch v·ªÅ blob
      if (base64.startsWith('http://') || base64.startsWith('https://')) {
        try {
          const response = await fetch(base64);
          const blob = await response.blob();
          const objectUrl = URL.createObjectURL(blob);
          
          img.onload = () => {
            URL.revokeObjectURL(objectUrl); // Clean up
            resolve(img);
          };
          img.onerror = (err) => reject(new Error('Kh√¥ng th·ªÉ load ·∫£nh: ' + err));
          img.src = objectUrl;
        } catch (error) {
          reject(new Error('L·ªói khi fetch ·∫£nh: ' + error.message));
        }
      } else {
        // Base64 string - load tr·ª±c ti·∫øp
        img.crossOrigin = 'anonymous';
        img.onload = () => resolve(img);
        img.onerror = (err) => reject(new Error('Kh√¥ng th·ªÉ load ·∫£nh: ' + err));
        img.src = base64;
      }
    });
  }

  /**
   * Helper: Capture ·∫£nh t·ª´ video element
   */
  captureFromVideo(videoElement) {
    const canvas = document.createElement('canvas');
    canvas.width = videoElement.videoWidth;
    canvas.height = videoElement.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(videoElement, 0, 0);
    return canvas.toDataURL('image/jpeg', 0.95);
  }

  /**
   * V·∫Ω face detection l√™n canvas (ƒë·ªÉ debug/preview)
   */
  async drawDetection(canvasElement, imageElement, detection) {
    if (!detection) return;

    const displaySize = {
      width: imageElement.width,
      height: imageElement.height,
    };

    faceapi.matchDimensions(canvasElement, displaySize);
    const resizedDetections = faceapi.resizeResults(detection, displaySize);
    
    canvasElement.getContext('2d').clearRect(0, 0, canvasElement.width, canvasElement.height);
    faceapi.draw.drawDetections(canvasElement, resizedDetections);
    faceapi.draw.drawFaceLandmarks(canvasElement, resizedDetections);
  }
}

export default new FaceRecognitionService();
