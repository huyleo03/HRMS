import * as faceapi from 'face-api.js';

class FaceRecognitionService {
  constructor() {
    this.isModelsLoaded = false;
    // Models ƒë√£ ƒë∆∞·ª£c clone v·ªÅ local b·∫±ng degit
    this.MODEL_URL = '/models';
    
    // Liveness Detection Configuration
    this.livenessConfig = {
      blinkThreshold: 0.25, // Eye Aspect Ratio threshold ƒë·ªÉ detect ch·ªõp m·∫Øt
      minBlinks: 1, // S·ªë l·∫ßn ch·ªõp m·∫Øt t·ªëi thi·ªÉu
      detectionTimeWindow: 5000, // 5 gi√¢y ƒë·ªÉ ho√†n th√†nh challenge
      headMovementThreshold: 15, // ƒê·ªô nghi√™ng ƒë·∫ßu t·ªëi thi·ªÉu (degrees)
    };
    
    // Tracking state for liveness detection
    this.livenessState = {
      blinkCount: 0,
      previousEAR: null,
      headPositions: [],
      challengeType: null, // 'blink' ho·∫∑c 'head_turn'
    };
  }

  /**
   * Load Face-API models (ch·ªâ load 1 l·∫ßn)
   */
  async loadModels() {
    if (this.isModelsLoaded) {
      console.log('‚úÖ Models already loaded');
      return;
    }

    try {
      console.log('üì• Loading Face-API models from:', this.MODEL_URL);
      
      // Load models - files n·∫±m tr·ª±c ti·∫øp trong /models (kh√¥ng c√≥ subfolder)
      await Promise.all([
        faceapi.nets.tinyFaceDetector.loadFromUri(this.MODEL_URL),
        faceapi.nets.faceLandmark68Net.loadFromUri(this.MODEL_URL),
        faceapi.nets.faceRecognitionNet.loadFromUri(this.MODEL_URL),
      ]);
      
      this.isModelsLoaded = true;
      console.log('‚úÖ Face-API models loaded successfully');
    } catch (error) {
      console.error('‚ùå Error loading Face-API models:', error);
      throw new Error('Kh√¥ng th·ªÉ t·∫£i models AI. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi internet.');
    }
  }

  /**
   * Detect face t·ª´ base64 image
   */
  async detectFace(base64Image) {
    await this.loadModels();

    try {
      // Convert base64 to Image element
      const img = await this.base64ToImage(base64Image);

      // Detect face v·ªõi descriptor
      const detection = await faceapi
        .detectSingleFace(img, new faceapi.TinyFaceDetectorOptions({
          inputSize: 320,
          scoreThreshold: 0.5
        }))
        .withFaceLandmarks()
        .withFaceDescriptor();

      return detection;
    } catch (error) {
      console.error('‚ùå Face detection error:', error);
      throw error;
    }
  }

  /**
   * So s√°nh 2 khu√¥n m·∫∑t
   * @param {string} profilePhoto - Base64 image t·ª´ profile
   * @param {string} checkInPhoto - Base64 image t·ª´ check-in
   * @param {number} threshold - Ng∆∞·ª°ng so s√°nh (0.4-0.7), c√†ng nh·ªè c√†ng kh·∫Øt khe
   * @returns {Object} K·∫øt qu·∫£ so s√°nh
   */
  async compareFaces(profilePhoto, checkInPhoto, threshold = 0.6) {
    try {
      console.log('üîç Starting face comparison...');
      await this.loadModels();

      // Detect faces t·ª´ c·∫£ 2 ·∫£nh
      console.log('üì∏ Detecting face in profile photo...');
      const profileDetection = await this.detectFace(profilePhoto);

      console.log('üì∏ Detecting face in check-in photo...');
      const checkInDetection = await this.detectFace(checkInPhoto);

      // Ki·ªÉm tra c√≥ detect ƒë∆∞·ª£c kh√¥ng
      if (!profileDetection) {
        return {
          success: false,
          isMatch: false,
          message: 'Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh h·ªì s∆°. Vui l√≤ng c·∫≠p nh·∫≠t ·∫£nh ƒë·∫°i di·ªán r√µ r√†ng h∆°n.',
          similarity: 0,
        };
      }

      if (!checkInDetection) {
        return {
          success: false,
          isMatch: false,
          message: 'Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh ch·∫•m c√¥ng. Vui l√≤ng ch·ª•p l·∫°i v·ªõi khu√¥n m·∫∑t r√µ r√†ng.',
          similarity: 0,
        };
      }

      // T√≠nh kho·∫£ng c√°ch Euclidean gi·ªØa 2 face descriptors
      const distance = faceapi.euclideanDistance(
        profileDetection.descriptor,
        checkInDetection.descriptor
      );

      // Convert distance sang % similarity
      const similarity = Math.max(0, ((1 - distance) * 100));
      const isMatch = distance < threshold;

      console.log('üìä Face comparison result:', {
        distance: distance.toFixed(4),
        similarity: similarity.toFixed(1) + '%',
        threshold,
        isMatch,
      });

      return {
        success: true,
        isMatch,
        distance: parseFloat(distance.toFixed(4)),
        similarity: parseFloat(similarity.toFixed(1)),
        threshold,
        message: isMatch
          ? `‚úÖ X√°c th·ª±c th√†nh c√¥ng! ƒê·ªô t∆∞∆°ng ƒë·ªìng: ${similarity.toFixed(1)}%`
          : `‚ùå Khu√¥n m·∫∑t kh√¥ng kh·ªõp! ƒê·ªô t∆∞∆°ng ƒë·ªìng: ${similarity.toFixed(1)}% (y√™u c·∫ßu t·ªëi thi·ªÉu ${((1 - threshold) * 100).toFixed(0)}%)`,
      };
    } catch (error) {
      console.error('‚ùå Face comparison error:', error);
      return {
        success: false,
        isMatch: false,
        message: 'L·ªói khi so s√°nh khu√¥n m·∫∑t: ' + error.message,
        similarity: 0,
      };
    }
  }

  /**
   * Helper: Convert base64 to Image element
   * N·∫øu l√† URL external, fetch qua proxy ƒë·ªÉ tr√°nh CORS
   */
  async base64ToImage(base64) {
    return new Promise(async (resolve, reject) => {
      const img = new Image();
      
      // N·∫øu l√† URL external (kh√¥ng ph·∫£i base64), fetch v·ªÅ blob
      if (base64.startsWith('http://') || base64.startsWith('https://')) {
        try {
          const response = await fetch(base64);
          const blob = await response.blob();
          const objectUrl = URL.createObjectURL(blob);
          
          img.onload = () => {
            URL.revokeObjectURL(objectUrl); // Clean up
            resolve(img);
          };
          img.onerror = (err) => reject(new Error('Kh√¥ng th·ªÉ load ·∫£nh: ' + err));
          img.src = objectUrl;
        } catch (error) {
          reject(new Error('L·ªói khi fetch ·∫£nh: ' + error.message));
        }
      } else {
        // Base64 string - load tr·ª±c ti·∫øp
        img.crossOrigin = 'anonymous';
        img.onload = () => resolve(img);
        img.onerror = (err) => reject(new Error('Kh√¥ng th·ªÉ load ·∫£nh: ' + err));
        img.src = base64;
      }
    });
  }

  /**
   * Helper: Capture ·∫£nh t·ª´ video element
   */
  captureFromVideo(videoElement) {
    const canvas = document.createElement('canvas');
    canvas.width = videoElement.videoWidth;
    canvas.height = videoElement.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(videoElement, 0, 0);
    return canvas.toDataURL('image/jpeg', 0.95);
  }

  /**
   * Helper: V·∫Ω face detection l√™n canvas (ƒë·ªÉ debug/preview)
   */
  async drawDetection(canvasElement, imageElement, detection) {
    if (!detection) return;

    const displaySize = {
      width: imageElement.width,
      height: imageElement.height,
    };

    faceapi.matchDimensions(canvasElement, displaySize);
    const resizedDetections = faceapi.resizeResults(detection, displaySize);
    
    canvasElement.getContext('2d').clearRect(0, 0, canvasElement.width, canvasElement.height);
    faceapi.draw.drawDetections(canvasElement, resizedDetections);
    faceapi.draw.drawFaceLandmarks(canvasElement, resizedDetections);
  }

  /**
   * ===========================================
   * üõ°Ô∏è LIVENESS DETECTION - CH·ªêNG GIAN L·∫¨N 
   * ===========================================
   */

  /**
   * T√≠nh Eye Aspect Ratio (EAR) ƒë·ªÉ detect ch·ªõp m·∫Øt
   * EAR < 0.25 = m·∫Øt ƒëang nh·∫Øm
   */
  calculateEAR(landmarks) {
    const leftEye = landmarks.getLeftEye();
    const rightEye = landmarks.getRightEye();

    const leftEAR = this.getEyeAspectRatio(leftEye);
    const rightEAR = this.getEyeAspectRatio(rightEye);

    return (leftEAR + rightEAR) / 2.0;
  }

  /**
   * C√¥ng th·ª©c EAR:
   * EAR = (||p2 - p6|| + ||p3 - p5||) / (2 * ||p1 - p4||)
   */
  getEyeAspectRatio(eyePoints) {
    const p1 = eyePoints[0];
    const p2 = eyePoints[1];
    const p3 = eyePoints[2];
    const p4 = eyePoints[3];
    const p5 = eyePoints[4];
    const p6 = eyePoints[5];

    const vertical1 = this.euclideanDistance(p2, p6);
    const vertical2 = this.euclideanDistance(p3, p5);
    const horizontal = this.euclideanDistance(p1, p4);

    return (vertical1 + vertical2) / (2.0 * horizontal);
  }

  euclideanDistance(p1, p2) {
    return Math.sqrt(Math.pow(p1.x - p2.x, 2) + Math.pow(p1.y - p2.y, 2));
  }

  /**
   * Detect ch·ªõp m·∫Øt t·ª´ video stream
   * @returns {Promise<boolean>} True n·∫øu detect ƒë∆∞·ª£c ch·ªõp m·∫Øt
   */
  async detectBlink(videoElement, onProgress) {
    return new Promise(async (resolve, reject) => {
      await this.loadModels();

      let blinkCount = 0;
      let isEyeClosed = false;
      const startTime = Date.now();
      const timeout = this.livenessConfig.detectionTimeWindow;

      const checkBlink = async () => {
        try {
          // Ki·ªÉm tra timeout
          if (Date.now() - startTime > timeout) {
            reject(new Error('‚è±Ô∏è H·∫øt th·ªùi gian! Vui l√≤ng th·ª≠ l·∫°i.'));
            return;
          }

          // Detect face v·ªõi landmarks
          const detection = await faceapi
            .detectSingleFace(videoElement, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks();

          if (!detection) {
            onProgress && onProgress({ message: 'üë§ Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t', blinkCount });
            requestAnimationFrame(checkBlink);
            return;
          }

          // T√≠nh EAR
          const ear = this.calculateEAR(detection.landmarks);

          // Detect tr·∫°ng th√°i m·∫Øt
          if (ear < this.livenessConfig.blinkThreshold) {
            // M·∫Øt ƒëang nh·∫Øm
            if (!isEyeClosed) {
              isEyeClosed = true;
            }
          } else {
            // M·∫Øt ƒëang m·ªü
            if (isEyeClosed) {
              // V·ª´a m·ªü m·∫Øt ‚Üí ƒê√£ ch·ªõp 1 l·∫ßn
              blinkCount++;
              isEyeClosed = false;

              onProgress && onProgress({
                message: `‚úÖ Ph√°t hi·ªán ch·ªõp m·∫Øt ${blinkCount}/${this.livenessConfig.minBlinks}`,
                blinkCount,
              });

              // ƒê·ªß s·ªë l·∫ßn ch·ªõp ‚Üí Success
              if (blinkCount >= this.livenessConfig.minBlinks) {
                resolve(true);
                return;
              }
            }
          }

          onProgress && onProgress({
            message: `üëÅÔ∏è Vui l√≤ng ch·ªõp m·∫Øt ${blinkCount}/${this.livenessConfig.minBlinks}`,
            blinkCount,
            ear: ear.toFixed(3),
          });

          // Continue checking
          requestAnimationFrame(checkBlink);
        } catch (error) {
          reject(error);
        }
      };

      // Start checking
      checkBlink();
    });
  }

  /**
   * T√≠nh g√≥c nghi√™ng ƒë·∫ßu (Head Pose Estimation)
   */
  calculateHeadPose(landmarks) {
    const nose = landmarks.getNose();
    const leftEye = landmarks.getLeftEye();
    const rightEye = landmarks.getRightEye();

    // T√≠nh trung ƒëi·ªÉm 2 m·∫Øt
    const eyeCenter = {
      x: (leftEye[0].x + rightEye[3].x) / 2,
      y: (leftEye[0].y + rightEye[3].y) / 2,
    };

    // T√≠nh vector t·ª´ m≈©i ƒë·∫øn trung ƒëi·ªÉm m·∫Øt
    const nosePoint = nose[3]; // Tip of nose
    const dx = nosePoint.x - eyeCenter.x;
    const dy = nosePoint.y - eyeCenter.y;

    // T√≠nh g√≥c yaw (xoay tr√°i/ph·∫£i)
    const yaw = Math.atan2(dx, dy) * (180 / Math.PI);

    return { yaw };
  }

  /**
   * Detect xoay ƒë·∫ßu
   * @param {string} direction - 'left' ho·∫∑c 'right'
   */
  async detectHeadTurn(videoElement, direction = 'left', onProgress) {
    return new Promise(async (resolve, reject) => {
      await this.loadModels();

      let centerYaw = null;
      let maxDeviation = 0;
      const startTime = Date.now();
      const timeout = this.livenessConfig.detectionTimeWindow;
      const threshold = this.livenessConfig.headMovementThreshold;

      const checkHeadTurn = async () => {
        try {
          if (Date.now() - startTime > timeout) {
            reject(new Error('‚è±Ô∏è H·∫øt th·ªùi gian! Vui l√≤ng th·ª≠ l·∫°i.'));
            return;
          }

          const detection = await faceapi
            .detectSingleFace(videoElement, new faceapi.TinyFaceDetectorOptions())
            .withFaceLandmarks();

          if (!detection) {
            onProgress && onProgress({ message: 'üë§ Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t' });
            requestAnimationFrame(checkHeadTurn);
            return;
          }

          const { yaw } = this.calculateHeadPose(detection.landmarks);

          // L·∫ßn ƒë·∫ßu ti√™n ‚Üí L∆∞u v·ªã tr√≠ trung t√¢m
          if (centerYaw === null) {
            centerYaw = yaw;
            onProgress && onProgress({
              message: `üì∏ Vui l√≤ng xoay ƒë·∫ßu sang ${direction === 'left' ? 'TR√ÅI' : 'PH·∫¢I'}`,
            });
            requestAnimationFrame(checkHeadTurn);
            return;
          }

          // T√≠nh ƒë·ªô l·ªách
          const deviation = yaw - centerYaw;
          maxDeviation = Math.max(maxDeviation, Math.abs(deviation));

          const expectedDeviation = direction === 'left' ? deviation < -threshold : deviation > threshold;

          if (expectedDeviation) {
            resolve(true);
            return;
          }

          onProgress && onProgress({
            message: `üîÑ ƒêang xoay... ${Math.abs(deviation).toFixed(0)}¬∞/${threshold}¬∞`,
            deviation: deviation.toFixed(1),
          });

          requestAnimationFrame(checkHeadTurn);
        } catch (error) {
          reject(error);
        }
      };

      checkHeadTurn();
    });
  }

  /**
   * MAIN FUNCTION: Liveness Check v·ªõi Random Challenge
   * @param {HTMLVideoElement} videoElement 
   * @param {Function} onProgress - Callback ƒë·ªÉ update UI
   * @returns {Promise<Object>}
   */
  async performLivenessCheck(videoElement, onProgress) {
    try {
      // Random challenge: 70% blink, 30% head turn
      const challenges = ['blink', 'blink', 'blink', 'head_turn'];
      const selectedChallenge = challenges[Math.floor(Math.random() * challenges.length)];

      console.log('üé≤ Selected challenge:', selectedChallenge);

      if (selectedChallenge === 'blink') {
        onProgress && onProgress({
          challengeType: 'blink',
          message: 'üëÅÔ∏è Vui l√≤ng CH·ªöP M·∫ÆT ƒë·ªÉ x√°c nh·∫≠n b·∫°n l√† ng∆∞·ªùi th·∫≠t',
        });

        await this.detectBlink(videoElement, onProgress);

        return {
          success: true,
          challengeType: 'blink',
          message: '‚úÖ X√°c th·ª±c th√†nh c√¥ng! B·∫°n l√† ng∆∞·ªùi th·∫≠t.',
        };
      } else {
        // Head turn (random left/right)
        const direction = Math.random() > 0.5 ? 'left' : 'right';

        onProgress && onProgress({
          challengeType: 'head_turn',
          direction,
          message: `üîÑ Vui l√≤ng XOAY ƒê·∫¶U SANG ${direction === 'left' ? 'TR√ÅI' : 'PH·∫¢I'}`,
        });

        await this.detectHeadTurn(videoElement, direction, onProgress);

        return {
          success: true,
          challengeType: 'head_turn',
          message: '‚úÖ X√°c th·ª±c th√†nh c√¥ng! B·∫°n l√† ng∆∞·ªùi th·∫≠t.',
        };
      }
    } catch (error) {
      console.error('‚ùå Liveness check failed:', error);
      return {
        success: false,
        message: error.message || 'X√°c th·ª±c th·∫•t b·∫°i. Vui l√≤ng th·ª≠ l·∫°i.',
      };
    }
  }

  /**
   * Ki·ªÉm tra ch·∫•t l∆∞·ª£ng ·∫£nh (ch·ªëng ·∫£nh m·ªù/t·ªëi)
   */
  async checkImageQuality(base64Image) {
    try {
      const img = await this.base64ToImage(base64Image);
      const canvas = document.createElement('canvas');
      canvas.width = img.width;
      canvas.height = img.height;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(img, 0, 0);

      const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
      const data = imageData.data;

      // T√≠nh ƒë·ªô s√°ng trung b√¨nh
      let totalBrightness = 0;
      for (let i = 0; i < data.length; i += 4) {
        const brightness = (data[i] + data[i + 1] + data[i + 2]) / 3;
        totalBrightness += brightness;
      }
      const avgBrightness = totalBrightness / (data.length / 4);

      // Ki·ªÉm tra
      if (avgBrightness < 50) {
        return { success: false, message: 'üåë ·∫¢nh qu√° t·ªëi! Vui l√≤ng ch·ª•p ·ªü n∆°i s√°ng h∆°n.' };
      }
      if (avgBrightness > 240) {
        return { success: false, message: '‚òÄÔ∏è ·∫¢nh qu√° s√°ng! Vui l√≤ng gi·∫£m √°nh s√°ng.' };
      }

      return { success: true, brightness: avgBrightness.toFixed(0) };
    } catch (error) {
      return { success: false, message: 'Kh√¥ng th·ªÉ ki·ªÉm tra ch·∫•t l∆∞·ª£ng ·∫£nh' };
    }
  }
}

const faceRecognitionService = new FaceRecognitionService();
export default faceRecognitionService;
